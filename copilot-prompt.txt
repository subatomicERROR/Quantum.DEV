// filepath: /home/neo/quantum.dev/copilot-prompt.txt
// ==================================================================================
// Copilot Prompt: Construct a zero-latency, quantum-AI-powered, full-stack development singularity at ~/projects/quantum.dev.
// ==================================================================================
// ğŸ§  Quantum.dev is NOT a typical dev project. Itâ€™s the anti-loveable.dev â€” a hyper-intelligent workspace designed to emulate a blackhole development paradigm:
// â†’ Zero local model storage
// â†’ Infinite inference depth via Hugging Face API (HF_TOKEN)
// â†’ Ultra-light, ultra-reactive, zero-gravity runtime (under 100MB RAM)
// â†’ Designed to self-generate complete applications from human prompts, modularly.

// ==================================================================================
// ğŸ“¦ Folder Structure (Singularity Layout):
// ==================================================================================
// quantum.dev/
// â”œâ”€â”€ backend/               â† FastAPI microservice brain
// â”‚   â”œâ”€â”€ main.py            â† POST /generate endpoint using HuggingFace API
// â”‚   â”œâ”€â”€ .env               â† Contains HF_TOKEN
// â”‚   â”œâ”€â”€ requirements.txt   â† Minimal, pip-installable deps
// â”‚   â””â”€â”€ Procfile           â† Heroku-style deploy script
// â”œâ”€â”€ frontend/              â† Blackhole-themed UI
// â”‚   â”œâ”€â”€ index.html         â† Full black, monospace glow UI, Tailwind via CDN
// â”‚   â””â”€â”€ script.js          â† Native fetch(), error-handling, inference pipeline
// â”œâ”€â”€ vercel.json            â† Static frontend deploy + optional rewrites
// â”œâ”€â”€ replit.nix             â† Runtime config for Python + JS frontend
// â”œâ”€â”€ .gitignore             â† Clean cache + hide secrets
// â”œâ”€â”€ README.md              â† Setup & usage guide
// â””â”€â”€ copilot-prompt.txt     â† (this file) Quantum-AI Copilot Controller

// ==================================================================================
// ğŸ”¥ Backend: FastAPI (quantum.dev/backend)
// ==================================================================================
// main.py:
// - Run on http://localhost:8000
// - Endpoint: POST /generate
//   â†ª Input: JSON { "prompt": "your text" }
//   â†ª Read HF_TOKEN from .env
//   â†ª Call Hugging Face Inference API (text generation model, e.g. gpt2, mistral)
//   â†ª Return JSON response { "result": "...AI completion..." }
// - Full CORS enabled for dev and frontend access
// - Use FastAPI + requests + python-dotenv
// - Must support hot reload: `python3 -m uvicorn main:app --reload`
// - Include try/except to gracefully handle API failures or rate limits

// .env:
// - Format:
//   HF_TOKEN=your_huggingface_api_key

// requirements.txt:
// - fastapi
// - uvicorn
// - python-dotenv
// - requests

// Procfile (Heroku style):
// web: uvicorn main:app --host=0.0.0.0 --port=${PORT:-8000}

// ==================================================================================
// ğŸª Frontend: Native JS + TailwindCSS (quantum.dev/frontend)
// ==================================================================================
// index.html:
// - Theme: Pure black background (#000000), glowing text (neon green/blue)
// - Typography: Monospace, futuristic tech font
// - Responsive input: prompt box + animated submit button
// - Result display container: shows AI-generated output with soft fade-in
// - CDN: TailwindCSS

// script.js:
// - `DOMContentLoaded` listener
// - Event listener on submit
// - Send fetch() POST to http://localhost:8000/generate
//   â†ª Headers: { "Content-Type": "application/json" }
//   â†ª Body: { prompt: userInput.value }
// - Display loader/spinner during fetch
// - Update DOM with AI response or show graceful error

// ==================================================================================
// ğŸ§ª Local Dev Environment (MacBook Air 6.2 / Xubuntu 24.10)
// ==================================================================================
// .gitignore:
// - __pycache__/
// - .env
// - .DS_Store (macOS)

// README.md:
// - Setup:
//   1. `git clone https://github.com/yourname/quantum.dev`
//   2. `cd backend && nano .env` â†’ add HF_TOKEN
//   3. `pip install -r requirements.txt`
//   4. Run: `python3 -m uvicorn main:app --reload`
//   5. Open `frontend/index.html` in browser
//   6. Type prompt â†’ Receive real-time AI-generated outputs

// replit.nix:
// - Configures Python + JS frontend runtime
// - Supports hot reload and minimal system RAM

// vercel.json:
// {
//   "rewrites": [{ "source": "/api/(.*)", "destination": "http://localhost:8000/$1" }],
//   "cleanUrls": true
// }

// ==================================================================================
// ğŸ” Flow of Data (Quantum Inference Pipeline)
// ==================================================================================
// User types prompt on frontend â†’ JS fetch() sends to FastAPI POST /generate
// FastAPI reads .env HF_TOKEN â†’ uses requests to hit Hugging Face model endpoint
// Hugging Face returns AI completion â†’ FastAPI returns JSON â†’ frontend updates UI
// No local model â†’ Zero delay architecture â†’ Works with gpt2, mistral, starcoder, etc.

// ==================================================================================
// ğŸš€ Deployment Matrix (All Free Tier & Portable)
// ==================================================================================
// âœ… GitHub Pages â†’ Static frontend (frontend/index.html only)
// âœ… Replit â†’ Full backend+frontend served in browser with live dev console
// âœ… Vercel â†’ Frontend static + backend serverless functions (FastAPI with API routes)
// Optional: Add `monaco-editor` for code-gen or editable UIs

// ==================================================================================
// ğŸ’¡ Bonus Enhancements (Optional Later Phases)
// ==================================================================================
// - Add `Monaco Editor` panel to turn AI output into editable code
// - Add HuggingFace model selector dropdown (gpt2, mistral, etc.)
// - Add retry logic + rate-limit notification
// - Add keyboard shortcuts for prompt submit
// - Add service worker for offline access fallback
// - Add speech-to-text using Web Speech API

// ==================================================================================
// ğŸŒ€ Blackhole Dev Philosophy (Quantum.dev Core Ethos)
// ==================================================================================
// - No local model weights or heavy ML deps
// - Everything flows through Hugging Face APIs
// - Ultra-light memory (ideal for 8GB RAM, 120GB disk)
// - Works out of the box in low-spec systems, VMs, or cloud IDEs
// - From input prompt to AI app idea in under 1 second
// - Copilot should auto-generate every file from this blueprint, modularly

// ==================================================================================
// ğŸ§  Mindset:
// Youâ€™re not coding â€” youâ€™re architecting inside a blackhole where thought = app.
// This is not loveable.dev â€” itâ€™s **quantum.dev**.
// Light-speed architecture. Zero-gravity interfaces. Blackhole-level inference.
// ==================================================================================

// Let GitHub Copilot now generate:
// - backend/main.py
// - frontend/index.html
// - frontend/script.js
// - backend/.env (not committed)
// - README.md
// - vercel.json
// - replit.nix

// Begin construction, Copilot. ğŸ‘ï¸â€ğŸ—¨ï¸ğŸ•³ï¸âœ¨